{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6adc1a",
   "metadata": {},
   "source": [
    "# Wafer Defect Detection - Model Training\n",
    "This notebook contains the complete training pipeline for the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"ðŸŽ¯ MANUAL DATA LOADING - No tf.data bugs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ae863",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT PATH\n",
    "DATASET_DIR = \"/kaggle/input/data-v2\"  # From your screenshot\n",
    "\n",
    "# Find ALL class folders (recursive)\n",
    "class_folders = defaultdict(list)\n",
    "for root, dirs, files in os.walk(DATASET_DIR):\n",
    "    if root != DATASET_DIR and len(files) > 0:\n",
    "        rel_path = os.path.relpath(root, DATASET_DIR)\n",
    "        class_name = os.path.basename(root)\n",
    "        class_folders[class_name].extend([os.path.join(root, f) for f in files])\n",
    "\n",
    "class_names = sorted(class_folders.keys())\n",
    "print(f\"âœ… Found {len(class_names)} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64da999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images manually\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    img_paths = class_folders[class_name][:500]  # Limit per class for memory\n",
    "    print(f\"Loading {class_name}: {len(img_paths)} images\")\n",
    "\n",
    "    for path in img_paths:\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=1, expand_animations=False)\n",
    "        img = tf.image.resize(img, [64, 64])\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        all_images.append(img)\n",
    "        all_labels.append(idx)\n",
    "\n",
    "print(f\"\\nâœ… Total: {len(all_images)} images loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726cf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X = np.array(all_images)  # [N, 64, 64, 1]\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"Classes in data: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb387023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual train/val split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "y_train, y_val = y[:split], y[split:]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95066ace",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with CORRECT output classes\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(64, 64, 1)),\n",
    "    layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # FIXED\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9d2a2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1897c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN - Pure numpy arrays = NO BUGS\n",
    "print(\"\\nðŸš€ TRAINING (this WILL work)...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val),  # TUPLE not list\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c9d5d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "print(\"\\nâœ… FINAL TEST:\")\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"val_loss: {val_loss:.4f}, val_accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5da340",
   "metadata": {},
   "source": [
    "## Export to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e366f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFLite\n",
    "print(\"\\nðŸ”§ TFLite...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('/kaggle/working/defect_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "size = os.path.getsize('/kaggle/working/defect_model.tflite') / 1024\n",
    "print(f\"âœ… TFLite: {size:.1f} KB - DOWNLOAD THIS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857734cb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Model Performance:**\n",
    "- **Training Accuracy:** 71.63%\n",
    "- **Validation Accuracy:** 18.06%\n",
    "- **Total Parameters:** 18,935 (73.96 KB)\n",
    "- **TFLite Model Size:** 26.1 KB (optimized for edge deployment)\n",
    "\n",
    "**Dataset Statistics:**\n",
    "- Total Images: 1800\n",
    "- Classes: 7 (clean, defective, test, train, training, validate, validation)\n",
    "- Training Set: 1440 images\n",
    "- Validation Set: 360 images\n",
    "- Image Size: 64Ã—64 (grayscale)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
